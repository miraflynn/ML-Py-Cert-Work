{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions\n",
    "- Lie: we're missing a bit at this point\n",
    "- Missing an activation function\n",
    "- We want the output to be between 0 and 1, but with random weights, we have no idea if that'll happen. Thus, activation function.\n",
    "\n",
    "Activation Functions:\n",
    "- Rectified Linear Unit (Relu): - y = min(0, x)\n",
    "    - puts values between 0 and inf\n",
    "- Hyperbolic Tangent (Tanh): y = tanh(x)\n",
    "    - puts values between -1 and 1\n",
    "- Sigmoid: y = 1/(1+e^(-x))\n",
    "    - puts values between 0 and 1\n",
    "- Other options exist\n",
    "\n",
    "- At each neuron, we apply activation function to the output of the neuron before sending to the next neuron\n",
    "    - neuron_i = f(sum from i=0 to n of w_i * x_i + b)\n",
    "    - f is activation function, rest is the sum from lesson 11\n",
    "- At output neuron, activation function is important because it decides the bounds of our output\n",
    "    - some number between -inf and inf isn't very useful\n",
    "- Point of activation function is to introduce complexity into the network\n",
    "    - Hard to explain until training process\n",
    "    - Allows us to pick up on more/different features\n",
    "\n",
    "### Loss function\n",
    "- also called cost function\n",
    "- To train, we give an input and an expected value, see whether the actual output matched the expected value, and modify the trained parameters based on that\n",
    "- Let's say for some input, we interpret an output of 0 to be Red, and our actual output is 0.7\n",
    "- Loss function calculates how far off our actual output is from the expected\n",
    "- Higher loss means move parameters more drastically, lower loss means move parameters less\n",
    "\n",
    "Loss Functions:\n",
    "- Mean Absolute Error: (sum from i=1 to n of abs(y_i - lambda(x_i)))/n\n",
    "    - Complicated af, don't mind that\n",
    "- Mean Absolute Error\n",
    "- Hinge Loss\n",
    "- Other options exist\n",
    "\n",
    "### Gradient Descent\n",
    "- By changing weights and biases, we make the network better or worse.\n",
    "- The loss function is used to decide whether the network is getting better or worse\n",
    "- we know gradient descent, we went to engineering school\n",
    "- When training, we make predictions, compare to expected values, calculate a gradient (the direction we need to move to minimize the loss function), then use a technique called backpropagation to step backwards through the network and update the weights and biases according to the weights we calculated\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
