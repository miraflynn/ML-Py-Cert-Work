{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inputs and outputs, both numbers\n",
    "- output classes: could do 0 or 1 for binary classes, or could do an output between 0 and 1 for each class, which is more flexible\n",
    "    - output between 0 and 1 for each class looks a lot like a probability distribution function, if the sum of the probabilities is 1\n",
    "- for regression tasks, can have 1 value output\n",
    "- in between input and output layers, we have a hidden layer, not observed when interacting with the model\n",
    "- each layer connected by weights\n",
    "- densely connected neural network/layer, each node of one layer is connected to each node of the next. Each connection is called a weight\n",
    "- weights are what are changed when training the model\n",
    "- generally can be between 0 and 1, but that's dependent on how you're setting up your model\n",
    "- also have biases, there's one bias in each layer which is connected to each node of the next layer\n",
    "- biases are also trainable, they are constant values, and the weights of their connections are always 1 (discussed later)\n",
    "- biases don't connect to anything from the previous layer\n",
    "- hidden nodes are weighted sums of previous layer nodes\n",
    "    - sum from i=0 to n of w_i * x_i + b\n",
    "    - w_i is weight of neuron i, x_i is value of neuron i, b is bias\n",
    "    - at start of model, the weights are random and don't mean anything, their values are changed and made to do something through training\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
